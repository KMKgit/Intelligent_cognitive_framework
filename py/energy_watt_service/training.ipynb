{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 680 (CNMeM is enabled with initial size: 55.0% of memory, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, os\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from IPython.core.debugger import Tracer\n",
    "from nilm import NILM_Trainer\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, TimeDistributedDense\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import GRU, SimpleRNN, LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras.callbacks import ModelCheckpoint, History\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_trained_dir = None\n",
    "# path_trained_dir = '../lstm/result/separate_100_timestep/train_201611_08_10_22'\n",
    "learning_rate = 1.0\n",
    "appl_list = ['fan', 'massager', 'hairdryer']\n",
    "appl_num = len(appl_list)\n",
    "input_dim = 1\n",
    "nb_classes = pow(2, appl_num)\n",
    "hidden_units = 10\n",
    "time_step=10\n",
    "validation_split = 0.1\n",
    "epoch = 3000\n",
    "batch_size = 128\n",
    "# repeat = 6\n",
    "shuffle_num = 50\n",
    "\n",
    "if shuffle_num == 0:\n",
    "    path_train = '../data/train_test/train_processed.csv' \n",
    "    path_test = '../data/train_test/test_processed.csv'\n",
    "else:\n",
    "    path_train = '../data/fan_mix_hair/train_%d_shuffled.csv'%shuffle_num\n",
    "    path_test = '../data/fan_mix_hair/test_%d_shuffled.csv'%shuffle_num\n",
    "\n",
    "# loss = \"mse\"\n",
    "loss = \"categorical_crossentropy\"\n",
    "output_activation = \"softmax\"\n",
    "\n",
    "def build_gru_model(input_dim, nb_classes, hidden_units):\n",
    "    print('Building a model ...')\n",
    "    model = Sequential()\n",
    "    model.add(GRU(hidden_units, input_dim=input_dim, return_sequences=True, init='he_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "#     model.add(GRU(hidden_units, input_dim=hidden_units, return_sequences=True, init='he_uniform'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    model.add(TimeDistributed(Dense(nb_classes)))\n",
    "    model.add(Activation(output_activation))\n",
    "    adadelta = Adadelta(lr=learning_rate)\n",
    "    model.compile(loss=loss, optimizer=adadelta, metrics=[\"accuracy\"])\n",
    "    print('End of Building a model ...')\n",
    "    return model\n",
    "\n",
    "def build_lstm_model(input_dim, nb_classes, hidden_units):\n",
    "    print('Building a model ...')\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_units, input_dim=input_dim, return_sequences=True, init='he_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(hidden_units, input_dim=hidden_units, return_sequences=True, init='he_uniform'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    model.add(TimeDistributed(Dense(nb_classes)))\n",
    "    model.add(Activation(output_activation))\n",
    "    adadelta = Adadelta(lr=learning_rate)\n",
    "    model.compile(loss=loss, optimizer=adadelta, metrics=[\"accuracy\"])\n",
    "    print('End of Building a model ...')\n",
    "    return model\n",
    "\n",
    "def build_rnn_model(input_dim, nb_classes, hidden_units):\n",
    "    print('Building a model ...')\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(hidden_units, input_dim=input_dim, return_sequences=True, init='he_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "#     model.add(SimpleRNN(hidden_units, input_dim=hidden_units, return_sequences=True, init='he_uniform'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    model.add(TimeDistributed(Dense(nb_classes)))\n",
    "    model.add(Activation(output_activation))\n",
    "    adadelta = Adadelta(lr=learning_rate)\n",
    "    model.compile(loss=loss, optimizer=adadelta, metrics=[\"accuracy\"])\n",
    "    print('End of Building a model ...')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_list = [('gru', build_gru_model), ('lstm', build_lstm_model), ('simplernn', build_rnn_model)]\n",
    "# # train_list = [('lstm', build_lstm_model)]\n",
    "\n",
    "# target_dir = '../results/total/separate_%dtimestep_%dshuffled_%s_%s'%(time_step, shuffle_num, output_activation, loss)\n",
    "# os.mkdir( target_dir, 0755 );\n",
    "# for algorithm, build_model in train_list:    \n",
    "#     trainer = NILM_Trainer(path_train, path_test, build_model)\n",
    "#     model_dir = '%s/%s'%(target_dir, algorithm)\n",
    "#     os.mkdir( model_dir, 0755 );\n",
    "#     for i in range(repeat):\n",
    "        \n",
    "#         trainer.init(input_dim, nb_classes, model_dir, epoch=epoch, batch_size=batch_size, hidden_units=hidden_units,\n",
    "#                       time_step=time_step, learning_rate=learning_rate,\n",
    "#                       validation_split=validation_split, path_trained_dir=path_trained_dir)\n",
    "#         trainer.load_data()\n",
    "#         model, train_history = trainer.train()\n",
    "#         trainer.test(trainer.result_dir)\n",
    "#         path_trained_dir = trainer.result_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trainer.test(trainer.result_dir)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing After Training\n",
    "trainer = NILM_Trainer(path_train, path_test, build_lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./result/train_201611_11_16_53 is created\n",
      "hyper parameters initialized\n",
      "Building a model ...\n",
      "End of Building a model ...\n",
      "End of Building a model ...\n",
      "Max Ditionary generating ...\n",
      "Loading a dataset [../data/fan_mix_hair/train_50_shuffled.csv]...\n",
      "Loading a dataset [../data/fan_mix_hair/test_50_shuffled.csv]...\n",
      "Max Ditionary generated ...\n",
      "Normalizing ...\n",
      "shape of X:  (4000, 10, 1)\n",
      "shape of y:  (4000, 10, 8)\n",
      "End of load_data() ...\n",
      "Normalizing ...\n",
      "shape of X:  (4000, 10, 1)\n",
      "shape of y:  (4000, 10, 8)\n",
      "End of load_data() ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[-0.61],\n",
       "         [-0.62],\n",
       "         [-0.62],\n",
       "         ..., \n",
       "         [-0.62],\n",
       "         [-0.61],\n",
       "         [-0.62]],\n",
       " \n",
       "        [[-0.61],\n",
       "         [-0.62],\n",
       "         [-0.61],\n",
       "         ..., \n",
       "         [-0.61],\n",
       "         [-0.61],\n",
       "         [-0.61]],\n",
       " \n",
       "        [[-0.62],\n",
       "         [-0.61],\n",
       "         [-0.62],\n",
       "         ..., \n",
       "         [-0.62],\n",
       "         [-0.61],\n",
       "         [-0.61]],\n",
       " \n",
       "        ..., \n",
       "        [[-0.02],\n",
       "         [-0.01],\n",
       "         [-0.02],\n",
       "         ..., \n",
       "         [-0.02],\n",
       "         [-0.01],\n",
       "         [ 0.  ]],\n",
       " \n",
       "        [[-0.02],\n",
       "         [ 0.  ],\n",
       "         [-0.01],\n",
       "         ..., \n",
       "         [-0.02],\n",
       "         [-0.02],\n",
       "         [ 0.  ]],\n",
       " \n",
       "        [[-0.02],\n",
       "         [-0.01],\n",
       "         [-0.01],\n",
       "         ..., \n",
       "         [-0.01],\n",
       "         [-0.02],\n",
       "         [ 0.  ]]]), array([[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        ..., \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  1.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  1.]]]), array([[[-1.  ],\n",
       "         [-1.  ],\n",
       "         [-1.  ],\n",
       "         ..., \n",
       "         [-1.  ],\n",
       "         [-1.  ],\n",
       "         [-1.  ]],\n",
       " \n",
       "        [[-1.  ],\n",
       "         [-1.  ],\n",
       "         [-1.  ],\n",
       "         ..., \n",
       "         [-1.  ],\n",
       "         [-1.  ],\n",
       "         [-1.  ]],\n",
       " \n",
       "        [[-1.  ],\n",
       "         [-1.  ],\n",
       "         [-1.  ],\n",
       "         ..., \n",
       "         [-1.  ],\n",
       "         [-1.  ],\n",
       "         [-1.  ]],\n",
       " \n",
       "        ..., \n",
       "        [[-0.09],\n",
       "         [-0.07],\n",
       "         [-0.08],\n",
       "         ..., \n",
       "         [-0.08],\n",
       "         [-0.08],\n",
       "         [-0.09]],\n",
       " \n",
       "        [[-0.08],\n",
       "         [-0.08],\n",
       "         [-0.08],\n",
       "         ..., \n",
       "         [-0.08],\n",
       "         [-0.08],\n",
       "         [-0.07]],\n",
       " \n",
       "        [[-0.07],\n",
       "         [-0.09],\n",
       "         [-0.07],\n",
       "         ..., \n",
       "         [-0.08],\n",
       "         [-0.08],\n",
       "         [-0.08]]]), array([[[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        ..., \n",
       "        [[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  1.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  1.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  1.,  0.,  0.]]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.init(input_dim, nb_classes, target_dir='./result', epoch=epoch, batch_size=batch_size, hidden_units=hidden_units,\n",
    "              time_step=time_step, learning_rate=learning_rate,\n",
    "              validation_split=validation_split, path_trained_dir=path_trained_dir)\n",
    "trainer.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Train on 3600 samples, validate on 400 samples\n",
      "Epoch 1/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.1398 - acc: 0.1570Epoch 00000: val_loss improved from inf to 2.09915, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 2.1401 - acc: 0.1564 - val_loss: 2.0991 - val_acc: 0.1670\n",
      "Epoch 2/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.1220 - acc: 0.1458Epoch 00001: val_loss improved from 2.09915 to 2.08293, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 2.1223 - acc: 0.1453 - val_loss: 2.0829 - val_acc: 0.1500\n",
      "Epoch 3/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.1051 - acc: 0.1327Epoch 00002: val_loss improved from 2.08293 to 2.06779, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 2.1054 - acc: 0.1322 - val_loss: 2.0678 - val_acc: 0.1500\n",
      "Epoch 4/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.0905 - acc: 0.1305Epoch 00003: val_loss improved from 2.06779 to 2.05278, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 2.0908 - acc: 0.1299 - val_loss: 2.0528 - val_acc: 0.1500\n",
      "Epoch 5/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.0749 - acc: 0.1310Epoch 00004: val_loss improved from 2.05278 to 2.03726, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 2.0752 - acc: 0.1305 - val_loss: 2.0373 - val_acc: 0.1500\n",
      "Epoch 6/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.0596 - acc: 0.1331Epoch 00005: val_loss improved from 2.03726 to 2.02083, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 2.0598 - acc: 0.1326 - val_loss: 2.0208 - val_acc: 0.1500\n",
      "Epoch 7/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.0406 - acc: 0.1401Epoch 00006: val_loss improved from 2.02083 to 2.00215, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 2.0408 - acc: 0.1396 - val_loss: 2.0021 - val_acc: 0.1500\n",
      "Epoch 8/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 2.0208 - acc: 0.1571Epoch 00007: val_loss improved from 2.00215 to 1.98108, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 2.0211 - acc: 0.1566 - val_loss: 1.9811 - val_acc: 0.1737\n",
      "Epoch 9/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 1.9987 - acc: 0.1767Epoch 00008: val_loss improved from 1.98108 to 1.95590, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.9976 - acc: 0.1779 - val_loss: 1.9559 - val_acc: 0.1900\n",
      "Epoch 10/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 1.9694 - acc: 0.2081Epoch 00009: val_loss improved from 1.95590 to 1.92469, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.9695 - acc: 0.2074 - val_loss: 1.9247 - val_acc: 0.2025\n",
      "Epoch 11/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 1.9315 - acc: 0.2423Epoch 00010: val_loss improved from 1.92469 to 1.88257, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.9316 - acc: 0.2417 - val_loss: 1.8826 - val_acc: 0.2758\n",
      "Epoch 12/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 1.8827 - acc: 0.2791Epoch 00011: val_loss improved from 1.88257 to 1.82373, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.8827 - acc: 0.2788 - val_loss: 1.8237 - val_acc: 0.3167\n",
      "Epoch 13/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 1.8235 - acc: 0.3110Epoch 00012: val_loss improved from 1.82373 to 1.75876, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.8212 - acc: 0.3148 - val_loss: 1.7588 - val_acc: 0.3397\n",
      "Epoch 14/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 1.7549 - acc: 0.3359Epoch 00013: val_loss improved from 1.75876 to 1.69143, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.7548 - acc: 0.3359 - val_loss: 1.6914 - val_acc: 0.3762\n",
      "Epoch 15/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 1.6873 - acc: 0.3580Epoch 00014: val_loss improved from 1.69143 to 1.62243, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.6871 - acc: 0.3584 - val_loss: 1.6224 - val_acc: 0.3937\n",
      "Epoch 16/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 1.6221 - acc: 0.3764Epoch 00015: val_loss improved from 1.62243 to 1.55423, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.6188 - acc: 0.3805 - val_loss: 1.5542 - val_acc: 0.4315\n",
      "Epoch 17/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 1.5561 - acc: 0.3952Epoch 00016: val_loss improved from 1.55423 to 1.48805, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.5559 - acc: 0.3954 - val_loss: 1.4880 - val_acc: 0.4458\n",
      "Epoch 18/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 1.4967 - acc: 0.4095Epoch 00017: val_loss improved from 1.48805 to 1.42119, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.4933 - acc: 0.4137 - val_loss: 1.4212 - val_acc: 0.4870\n",
      "Epoch 19/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 1.4321 - acc: 0.4348Epoch 00018: val_loss improved from 1.42119 to 1.35456, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.4316 - acc: 0.4353 - val_loss: 1.3546 - val_acc: 0.4838\n",
      "Epoch 20/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 1.3744 - acc: 0.4517Epoch 00019: val_loss improved from 1.35456 to 1.29111, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.3737 - acc: 0.4523 - val_loss: 1.2911 - val_acc: 0.5020\n",
      "Epoch 21/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 1.3235 - acc: 0.4628Epoch 00020: val_loss improved from 1.29111 to 1.23488, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.3229 - acc: 0.4633 - val_loss: 1.2349 - val_acc: 0.5360\n",
      "Epoch 22/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 1.2761 - acc: 0.4876Epoch 00021: val_loss improved from 1.23488 to 1.18540, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.2734 - acc: 0.4911 - val_loss: 1.1854 - val_acc: 0.5928\n",
      "Epoch 23/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 1.2365 - acc: 0.5133Epoch 00022: val_loss improved from 1.18540 to 1.14296, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.2359 - acc: 0.5137 - val_loss: 1.1430 - val_acc: 0.6420\n",
      "Epoch 24/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 1.2086 - acc: 0.5218Epoch 00023: val_loss improved from 1.14296 to 1.10983, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.2081 - acc: 0.5221 - val_loss: 1.1098 - val_acc: 0.6528\n",
      "Epoch 25/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 1.1801 - acc: 0.5340Epoch 00024: val_loss improved from 1.10983 to 1.08180, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.1797 - acc: 0.5345 - val_loss: 1.0818 - val_acc: 0.6620\n",
      "Epoch 26/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 1.1547 - acc: 0.5453Epoch 00025: val_loss improved from 1.08180 to 1.05907, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.1541 - acc: 0.5457 - val_loss: 1.0591 - val_acc: 0.6637\n",
      "Epoch 27/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 1.1366 - acc: 0.5518Epoch 00026: val_loss improved from 1.05907 to 1.03655, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.1348 - acc: 0.5543 - val_loss: 1.0365 - val_acc: 0.6795\n",
      "Epoch 28/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 1.1167 - acc: 0.5563Epoch 00027: val_loss improved from 1.03655 to 1.01890, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.1154 - acc: 0.5581 - val_loss: 1.0189 - val_acc: 0.6817\n",
      "Epoch 29/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 1.1008 - acc: 0.5681Epoch 00028: val_loss improved from 1.01890 to 1.00160, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.0990 - acc: 0.5707 - val_loss: 1.0016 - val_acc: 0.6918\n",
      "Epoch 30/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 1.0877 - acc: 0.5663Epoch 00029: val_loss improved from 1.00160 to 0.98597, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.0869 - acc: 0.5678 - val_loss: 0.9860 - val_acc: 0.6867\n",
      "Epoch 31/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 1.0733 - acc: 0.5741Epoch 00030: val_loss improved from 0.98597 to 0.97308, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.0723 - acc: 0.5756 - val_loss: 0.9731 - val_acc: 0.6947\n",
      "Epoch 32/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 1.0642 - acc: 0.5794Epoch 00031: val_loss improved from 0.97308 to 0.96088, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.0640 - acc: 0.5796 - val_loss: 0.9609 - val_acc: 0.6943\n",
      "Epoch 33/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 1.0506 - acc: 0.5863Epoch 00032: val_loss improved from 0.96088 to 0.94985, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.0501 - acc: 0.5879 - val_loss: 0.9498 - val_acc: 0.7030\n",
      "Epoch 34/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 1.0406 - acc: 0.5893Epoch 00033: val_loss improved from 0.94985 to 0.93906, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.0397 - acc: 0.5911 - val_loss: 0.9391 - val_acc: 0.7135\n",
      "Epoch 35/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 1.0291 - acc: 0.5962Epoch 00034: val_loss improved from 0.93906 to 0.92853, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.0284 - acc: 0.5979 - val_loss: 0.9285 - val_acc: 0.7200\n",
      "Epoch 36/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 1.0232 - acc: 0.5956Epoch 00035: val_loss improved from 0.92853 to 0.92018, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.0223 - acc: 0.5974 - val_loss: 0.9202 - val_acc: 0.7232\n",
      "Epoch 37/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 1.0125 - acc: 0.6019Epoch 00036: val_loss improved from 0.92018 to 0.91102, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.0121 - acc: 0.6022 - val_loss: 0.9110 - val_acc: 0.7300\n",
      "Epoch 38/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 1.0036 - acc: 0.6083Epoch 00037: val_loss improved from 0.91102 to 0.90059, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 1.0031 - acc: 0.6085 - val_loss: 0.9006 - val_acc: 0.7353\n",
      "Epoch 39/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.9954 - acc: 0.6108Epoch 00038: val_loss improved from 0.90059 to 0.89418, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.9950 - acc: 0.6124 - val_loss: 0.8942 - val_acc: 0.7400\n",
      "Epoch 40/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.9870 - acc: 0.6152Epoch 00039: val_loss improved from 0.89418 to 0.88577, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.9869 - acc: 0.6153 - val_loss: 0.8858 - val_acc: 0.7377\n",
      "Epoch 41/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.9784 - acc: 0.6201Epoch 00040: val_loss improved from 0.88577 to 0.87848, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.9781 - acc: 0.6203 - val_loss: 0.8785 - val_acc: 0.7478\n",
      "Epoch 42/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.9701 - acc: 0.6260Epoch 00041: val_loss improved from 0.87848 to 0.87148, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.9700 - acc: 0.6259 - val_loss: 0.8715 - val_acc: 0.7565\n",
      "Epoch 43/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.9644 - acc: 0.6283Epoch 00042: val_loss improved from 0.87148 to 0.86531, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.9643 - acc: 0.6283 - val_loss: 0.8653 - val_acc: 0.7628\n",
      "Epoch 44/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.9593 - acc: 0.6306Epoch 00043: val_loss improved from 0.86531 to 0.86026, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.9593 - acc: 0.6306 - val_loss: 0.8603 - val_acc: 0.7705\n",
      "Epoch 45/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.9517 - acc: 0.6367Epoch 00044: val_loss improved from 0.86026 to 0.85239, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.9515 - acc: 0.6367 - val_loss: 0.8524 - val_acc: 0.7700\n",
      "Epoch 46/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.9448 - acc: 0.6371Epoch 00045: val_loss improved from 0.85239 to 0.84591, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.9446 - acc: 0.6373 - val_loss: 0.8459 - val_acc: 0.7708\n",
      "Epoch 47/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.9419 - acc: 0.6390Epoch 00046: val_loss improved from 0.84591 to 0.84126, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.9418 - acc: 0.6390 - val_loss: 0.8413 - val_acc: 0.7743\n",
      "Epoch 48/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.9338 - acc: 0.6422Epoch 00047: val_loss improved from 0.84126 to 0.83572, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.9338 - acc: 0.6421 - val_loss: 0.8357 - val_acc: 0.7785\n",
      "Epoch 49/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.9304 - acc: 0.6418Epoch 00048: val_loss improved from 0.83572 to 0.83055, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.9298 - acc: 0.6433 - val_loss: 0.8306 - val_acc: 0.7975\n",
      "Epoch 50/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.9244 - acc: 0.6456Epoch 00049: val_loss improved from 0.83055 to 0.82691, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.9238 - acc: 0.6467 - val_loss: 0.8269 - val_acc: 0.7947\n",
      "Epoch 51/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.9214 - acc: 0.6502Epoch 00050: val_loss improved from 0.82691 to 0.81998, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.9214 - acc: 0.6501 - val_loss: 0.8200 - val_acc: 0.7875\n",
      "Epoch 52/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.9131 - acc: 0.6526Epoch 00051: val_loss improved from 0.81998 to 0.81660, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.9133 - acc: 0.6523 - val_loss: 0.8166 - val_acc: 0.7940\n",
      "Epoch 53/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.9110 - acc: 0.6549Epoch 00052: val_loss improved from 0.81660 to 0.81282, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.9107 - acc: 0.6551 - val_loss: 0.8128 - val_acc: 0.8062\n",
      "Epoch 54/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.9051 - acc: 0.6617Epoch 00053: val_loss improved from 0.81282 to 0.80724, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.9051 - acc: 0.6618 - val_loss: 0.8072 - val_acc: 0.8045\n",
      "Epoch 55/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.9023 - acc: 0.6608Epoch 00054: val_loss improved from 0.80724 to 0.80195, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.9021 - acc: 0.6609 - val_loss: 0.8019 - val_acc: 0.8085\n",
      "Epoch 56/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.8965 - acc: 0.6658Epoch 00055: val_loss improved from 0.80195 to 0.79826, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8966 - acc: 0.6656 - val_loss: 0.7983 - val_acc: 0.8140\n",
      "Epoch 57/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.8904 - acc: 0.6696Epoch 00056: val_loss improved from 0.79826 to 0.79338, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8903 - acc: 0.6697 - val_loss: 0.7934 - val_acc: 0.8118\n",
      "Epoch 58/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.8865 - acc: 0.6709Epoch 00057: val_loss improved from 0.79338 to 0.78849, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8863 - acc: 0.6717 - val_loss: 0.7885 - val_acc: 0.8075\n",
      "Epoch 59/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.8826 - acc: 0.6778Epoch 00058: val_loss improved from 0.78849 to 0.78481, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8827 - acc: 0.6778 - val_loss: 0.7848 - val_acc: 0.8107\n",
      "Epoch 60/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.8758 - acc: 0.6783Epoch 00059: val_loss improved from 0.78481 to 0.77874, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8757 - acc: 0.6783 - val_loss: 0.7787 - val_acc: 0.8098\n",
      "Epoch 61/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.8730 - acc: 0.6802Epoch 00060: val_loss improved from 0.77874 to 0.77592, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8730 - acc: 0.6800 - val_loss: 0.7759 - val_acc: 0.8162\n",
      "Epoch 62/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.8673 - acc: 0.6838Epoch 00061: val_loss improved from 0.77592 to 0.77044, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8671 - acc: 0.6840 - val_loss: 0.7704 - val_acc: 0.8202\n",
      "Epoch 63/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.8656 - acc: 0.6807Epoch 00062: val_loss improved from 0.77044 to 0.76586, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8657 - acc: 0.6805 - val_loss: 0.7659 - val_acc: 0.8220\n",
      "Epoch 64/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.8606 - acc: 0.6836Epoch 00063: val_loss improved from 0.76586 to 0.76191, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8607 - acc: 0.6836 - val_loss: 0.7619 - val_acc: 0.8253\n",
      "Epoch 65/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.8558 - acc: 0.6835Epoch 00064: val_loss improved from 0.76191 to 0.75868, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8549 - acc: 0.6854 - val_loss: 0.7587 - val_acc: 0.8287\n",
      "Epoch 66/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.8529 - acc: 0.6881Epoch 00065: val_loss improved from 0.75868 to 0.75498, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8529 - acc: 0.6881 - val_loss: 0.7550 - val_acc: 0.8255\n",
      "Epoch 67/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.8477 - acc: 0.6893Epoch 00066: val_loss improved from 0.75498 to 0.75184, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8476 - acc: 0.6894 - val_loss: 0.7518 - val_acc: 0.8365\n",
      "Epoch 68/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.8461 - acc: 0.6899Epoch 00067: val_loss improved from 0.75184 to 0.74897, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8460 - acc: 0.6900 - val_loss: 0.7490 - val_acc: 0.8387\n",
      "Epoch 69/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.8423 - acc: 0.6926Epoch 00068: val_loss improved from 0.74897 to 0.74440, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8414 - acc: 0.6939 - val_loss: 0.7444 - val_acc: 0.8423\n",
      "Epoch 70/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.8371 - acc: 0.6986Epoch 00069: val_loss improved from 0.74440 to 0.73989, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8371 - acc: 0.6988 - val_loss: 0.7399 - val_acc: 0.8440\n",
      "Epoch 71/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.8344 - acc: 0.6977Epoch 00070: val_loss improved from 0.73989 to 0.73654, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8343 - acc: 0.6978 - val_loss: 0.7365 - val_acc: 0.8470\n",
      "Epoch 72/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.8287 - acc: 0.7024Epoch 00071: val_loss improved from 0.73654 to 0.73470, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8278 - acc: 0.7037 - val_loss: 0.7347 - val_acc: 0.8482\n",
      "Epoch 73/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.8270 - acc: 0.7005Epoch 00072: val_loss improved from 0.73470 to 0.72982, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8259 - acc: 0.7026 - val_loss: 0.7298 - val_acc: 0.8490\n",
      "Epoch 74/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.8227 - acc: 0.7007Epoch 00073: val_loss improved from 0.72982 to 0.72743, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8228 - acc: 0.7006 - val_loss: 0.7274 - val_acc: 0.8507\n",
      "Epoch 75/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.8211 - acc: 0.7036Epoch 00074: val_loss improved from 0.72743 to 0.72235, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8202 - acc: 0.7049 - val_loss: 0.7224 - val_acc: 0.8550\n",
      "Epoch 76/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.8185 - acc: 0.7024Epoch 00075: val_loss improved from 0.72235 to 0.72122, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8177 - acc: 0.7035 - val_loss: 0.7212 - val_acc: 0.8560\n",
      "Epoch 77/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.8111 - acc: 0.7093Epoch 00076: val_loss improved from 0.72122 to 0.71634, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8097 - acc: 0.7111 - val_loss: 0.7163 - val_acc: 0.8582\n",
      "Epoch 78/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.8074 - acc: 0.7110Epoch 00077: val_loss improved from 0.71634 to 0.71314, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8073 - acc: 0.7111 - val_loss: 0.7131 - val_acc: 0.8597\n",
      "Epoch 79/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.8059 - acc: 0.7122Epoch 00078: val_loss improved from 0.71314 to 0.70974, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8059 - acc: 0.7124 - val_loss: 0.7097 - val_acc: 0.8645\n",
      "Epoch 80/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.8012 - acc: 0.7146Epoch 00079: val_loss improved from 0.70974 to 0.70658, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.8011 - acc: 0.7148 - val_loss: 0.7066 - val_acc: 0.8677\n",
      "Epoch 81/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7984 - acc: 0.7166Epoch 00080: val_loss improved from 0.70658 to 0.70231, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7983 - acc: 0.7167 - val_loss: 0.7023 - val_acc: 0.8717\n",
      "Epoch 82/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7946 - acc: 0.7178Epoch 00081: val_loss improved from 0.70231 to 0.70041, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7944 - acc: 0.7180 - val_loss: 0.7004 - val_acc: 0.8712\n",
      "Epoch 83/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.7932 - acc: 0.7153Epoch 00082: val_loss improved from 0.70041 to 0.69504, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7924 - acc: 0.7162 - val_loss: 0.6950 - val_acc: 0.8760\n",
      "Epoch 84/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.7887 - acc: 0.7194Epoch 00083: val_loss improved from 0.69504 to 0.69182, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7878 - acc: 0.7208 - val_loss: 0.6918 - val_acc: 0.8772\n",
      "Epoch 85/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.7872 - acc: 0.7212Epoch 00084: val_loss improved from 0.69182 to 0.68835, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7867 - acc: 0.7221 - val_loss: 0.6884 - val_acc: 0.8788\n",
      "Epoch 86/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7810 - acc: 0.7240Epoch 00085: val_loss improved from 0.68835 to 0.68509, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7810 - acc: 0.7239 - val_loss: 0.6851 - val_acc: 0.8800\n",
      "Epoch 87/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7792 - acc: 0.7231Epoch 00086: val_loss improved from 0.68509 to 0.68089, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7791 - acc: 0.7232 - val_loss: 0.6809 - val_acc: 0.8840\n",
      "Epoch 88/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7767 - acc: 0.7257Epoch 00087: val_loss improved from 0.68089 to 0.67742, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7767 - acc: 0.7257 - val_loss: 0.6774 - val_acc: 0.8850\n",
      "Epoch 89/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7729 - acc: 0.7345Epoch 00088: val_loss improved from 0.67742 to 0.67419, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7728 - acc: 0.7345 - val_loss: 0.6742 - val_acc: 0.8867\n",
      "Epoch 90/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.7700 - acc: 0.7320Epoch 00089: val_loss improved from 0.67419 to 0.67042, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7686 - acc: 0.7332 - val_loss: 0.6704 - val_acc: 0.8870\n",
      "Epoch 91/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7645 - acc: 0.7372Epoch 00090: val_loss improved from 0.67042 to 0.66777, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7645 - acc: 0.7371 - val_loss: 0.6678 - val_acc: 0.8862\n",
      "Epoch 92/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7596 - acc: 0.7388Epoch 00091: val_loss improved from 0.66777 to 0.66657, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7594 - acc: 0.7389 - val_loss: 0.6666 - val_acc: 0.8832\n",
      "Epoch 93/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7582 - acc: 0.7372Epoch 00092: val_loss improved from 0.66657 to 0.66047, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7582 - acc: 0.7373 - val_loss: 0.6605 - val_acc: 0.8863\n",
      "Epoch 94/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7574 - acc: 0.7425Epoch 00093: val_loss improved from 0.66047 to 0.65680, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7573 - acc: 0.7426 - val_loss: 0.6568 - val_acc: 0.9028\n",
      "Epoch 95/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7526 - acc: 0.7432Epoch 00094: val_loss improved from 0.65680 to 0.65368, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7524 - acc: 0.7435 - val_loss: 0.6537 - val_acc: 0.9028\n",
      "Epoch 96/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.7474 - acc: 0.7456Epoch 00095: val_loss improved from 0.65368 to 0.65107, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7460 - acc: 0.7469 - val_loss: 0.6511 - val_acc: 0.9032\n",
      "Epoch 97/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.7454 - acc: 0.7457Epoch 00096: val_loss improved from 0.65107 to 0.64557, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7447 - acc: 0.7463 - val_loss: 0.6456 - val_acc: 0.9088\n",
      "Epoch 98/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7408 - acc: 0.7501Epoch 00097: val_loss improved from 0.64557 to 0.64224, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7407 - acc: 0.7501 - val_loss: 0.6422 - val_acc: 0.9095\n",
      "Epoch 99/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7351 - acc: 0.7525Epoch 00098: val_loss improved from 0.64224 to 0.63882, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7350 - acc: 0.7523 - val_loss: 0.6388 - val_acc: 0.9105\n",
      "Epoch 100/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7324 - acc: 0.7513Epoch 00099: val_loss improved from 0.63882 to 0.63508, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7322 - acc: 0.7515 - val_loss: 0.6351 - val_acc: 0.9110\n",
      "Epoch 101/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7346 - acc: 0.7500Epoch 00100: val_loss improved from 0.63508 to 0.63266, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7345 - acc: 0.7502 - val_loss: 0.6327 - val_acc: 0.9087\n",
      "Epoch 102/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7281 - acc: 0.7525Epoch 00101: val_loss improved from 0.63266 to 0.62876, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7279 - acc: 0.7527 - val_loss: 0.6288 - val_acc: 0.9097\n",
      "Epoch 103/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.7280 - acc: 0.7538Epoch 00102: val_loss improved from 0.62876 to 0.62587, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7272 - acc: 0.7541 - val_loss: 0.6259 - val_acc: 0.9092\n",
      "Epoch 104/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.7240 - acc: 0.7539Epoch 00103: val_loss improved from 0.62587 to 0.62228, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7232 - acc: 0.7547 - val_loss: 0.6223 - val_acc: 0.9092\n",
      "Epoch 105/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.7197 - acc: 0.7591Epoch 00104: val_loss improved from 0.62228 to 0.61907, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7187 - acc: 0.7602 - val_loss: 0.6191 - val_acc: 0.9093\n",
      "Epoch 106/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7163 - acc: 0.7574Epoch 00105: val_loss improved from 0.61907 to 0.61602, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7160 - acc: 0.7577 - val_loss: 0.6160 - val_acc: 0.9078\n",
      "Epoch 107/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.7148 - acc: 0.7577Epoch 00106: val_loss improved from 0.61602 to 0.61279, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7138 - acc: 0.7581 - val_loss: 0.6128 - val_acc: 0.9078\n",
      "Epoch 108/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.7111 - acc: 0.7620Epoch 00107: val_loss improved from 0.61279 to 0.60976, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7096 - acc: 0.7629 - val_loss: 0.6098 - val_acc: 0.9050\n",
      "Epoch 109/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.7075 - acc: 0.7571Epoch 00108: val_loss improved from 0.60976 to 0.60687, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7064 - acc: 0.7584 - val_loss: 0.6069 - val_acc: 0.9048\n",
      "Epoch 110/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.7027 - acc: 0.7635Epoch 00109: val_loss improved from 0.60687 to 0.60306, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.7024 - acc: 0.7637 - val_loss: 0.6031 - val_acc: 0.9045\n",
      "Epoch 111/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.6982 - acc: 0.7654Epoch 00110: val_loss improved from 0.60306 to 0.60039, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6980 - acc: 0.7656 - val_loss: 0.6004 - val_acc: 0.9048\n",
      "Epoch 112/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6988 - acc: 0.7604Epoch 00111: val_loss improved from 0.60039 to 0.59805, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6976 - acc: 0.7618 - val_loss: 0.5980 - val_acc: 0.9033\n",
      "Epoch 113/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6948 - acc: 0.7633Epoch 00112: val_loss improved from 0.59805 to 0.59273, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6939 - acc: 0.7639 - val_loss: 0.5927 - val_acc: 0.9022\n",
      "Epoch 114/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.6884 - acc: 0.7678Epoch 00113: val_loss improved from 0.59273 to 0.58966, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6882 - acc: 0.7680 - val_loss: 0.5897 - val_acc: 0.9020\n",
      "Epoch 115/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6866 - acc: 0.7661Epoch 00114: val_loss improved from 0.58966 to 0.58596, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6851 - acc: 0.7675 - val_loss: 0.5860 - val_acc: 0.9028\n",
      "Epoch 116/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.6832 - acc: 0.7696Epoch 00115: val_loss improved from 0.58596 to 0.58330, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6829 - acc: 0.7698 - val_loss: 0.5833 - val_acc: 0.9025\n",
      "Epoch 117/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6814 - acc: 0.7670Epoch 00116: val_loss improved from 0.58330 to 0.57921, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6806 - acc: 0.7676 - val_loss: 0.5792 - val_acc: 0.9017\n",
      "Epoch 118/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6752 - acc: 0.7727Epoch 00117: val_loss improved from 0.57921 to 0.57661, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6738 - acc: 0.7741 - val_loss: 0.5766 - val_acc: 0.9018\n",
      "Epoch 119/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.6716 - acc: 0.7729Epoch 00118: val_loss improved from 0.57661 to 0.57324, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6715 - acc: 0.7728 - val_loss: 0.5732 - val_acc: 0.9018\n",
      "Epoch 120/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.6712 - acc: 0.7731Epoch 00119: val_loss improved from 0.57324 to 0.57037, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6710 - acc: 0.7733 - val_loss: 0.5704 - val_acc: 0.9010\n",
      "Epoch 121/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6706 - acc: 0.7734Epoch 00120: val_loss improved from 0.57037 to 0.56693, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6689 - acc: 0.7749 - val_loss: 0.5669 - val_acc: 0.9010\n",
      "Epoch 122/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6664 - acc: 0.7739Epoch 00121: val_loss improved from 0.56693 to 0.56366, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6654 - acc: 0.7750 - val_loss: 0.5637 - val_acc: 0.9003\n",
      "Epoch 123/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6624 - acc: 0.7786Epoch 00122: val_loss improved from 0.56366 to 0.56053, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6613 - acc: 0.7797 - val_loss: 0.5605 - val_acc: 0.9000\n",
      "Epoch 124/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.6596 - acc: 0.7787Epoch 00123: val_loss improved from 0.56053 to 0.55753, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6596 - acc: 0.7788 - val_loss: 0.5575 - val_acc: 0.8983\n",
      "Epoch 125/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6575 - acc: 0.7782Epoch 00124: val_loss improved from 0.55753 to 0.55454, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6561 - acc: 0.7796 - val_loss: 0.5545 - val_acc: 0.8990\n",
      "Epoch 126/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6543 - acc: 0.7806Epoch 00125: val_loss improved from 0.55454 to 0.55066, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6534 - acc: 0.7814 - val_loss: 0.5507 - val_acc: 0.9043\n",
      "Epoch 127/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6515 - acc: 0.7787Epoch 00126: val_loss improved from 0.55066 to 0.54835, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6502 - acc: 0.7799 - val_loss: 0.5484 - val_acc: 0.9028\n",
      "Epoch 128/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6475 - acc: 0.7805Epoch 00127: val_loss improved from 0.54835 to 0.54490, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6461 - acc: 0.7817 - val_loss: 0.5449 - val_acc: 0.9202\n",
      "Epoch 129/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6434 - acc: 0.7859Epoch 00128: val_loss improved from 0.54490 to 0.54217, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6420 - acc: 0.7867 - val_loss: 0.5422 - val_acc: 0.9200\n",
      "Epoch 130/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6420 - acc: 0.7827Epoch 00129: val_loss improved from 0.54217 to 0.53908, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6409 - acc: 0.7835 - val_loss: 0.5391 - val_acc: 0.9225\n",
      "Epoch 131/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6383 - acc: 0.7840Epoch 00130: val_loss improved from 0.53908 to 0.53603, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6368 - acc: 0.7856 - val_loss: 0.5360 - val_acc: 0.9178\n",
      "Epoch 132/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.6357 - acc: 0.7857Epoch 00131: val_loss improved from 0.53603 to 0.53304, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6354 - acc: 0.7859 - val_loss: 0.5330 - val_acc: 0.9185\n",
      "Epoch 133/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6315 - acc: 0.7871Epoch 00132: val_loss improved from 0.53304 to 0.53066, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6301 - acc: 0.7888 - val_loss: 0.5307 - val_acc: 0.9237\n",
      "Epoch 134/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6293 - acc: 0.7865Epoch 00133: val_loss improved from 0.53066 to 0.52672, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6277 - acc: 0.7877 - val_loss: 0.5267 - val_acc: 0.9240\n",
      "Epoch 135/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6266 - acc: 0.7880Epoch 00134: val_loss improved from 0.52672 to 0.52393, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6250 - acc: 0.7895 - val_loss: 0.5239 - val_acc: 0.9187\n",
      "Epoch 136/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6257 - acc: 0.7870Epoch 00135: val_loss improved from 0.52393 to 0.52121, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6247 - acc: 0.7888 - val_loss: 0.5212 - val_acc: 0.9187\n",
      "Epoch 137/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.6223 - acc: 0.7889Epoch 00136: val_loss improved from 0.52121 to 0.51841, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6221 - acc: 0.7889 - val_loss: 0.5184 - val_acc: 0.9187\n",
      "Epoch 138/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.6154 - acc: 0.7936Epoch 00137: val_loss improved from 0.51841 to 0.51552, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6150 - acc: 0.7937 - val_loss: 0.5155 - val_acc: 0.9185\n",
      "Epoch 139/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.6156 - acc: 0.7921Epoch 00138: val_loss improved from 0.51552 to 0.51171, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6144 - acc: 0.7935 - val_loss: 0.5117 - val_acc: 0.9137\n",
      "Epoch 140/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.6093 - acc: 0.7958Epoch 00139: val_loss improved from 0.51171 to 0.50820, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6091 - acc: 0.7957 - val_loss: 0.5082 - val_acc: 0.9142\n",
      "Epoch 141/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.6067 - acc: 0.7955Epoch 00140: val_loss improved from 0.50820 to 0.50483, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6066 - acc: 0.7955 - val_loss: 0.5048 - val_acc: 0.9165\n",
      "Epoch 142/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.6061 - acc: 0.7965Epoch 00141: val_loss improved from 0.50483 to 0.50185, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6060 - acc: 0.7967 - val_loss: 0.5019 - val_acc: 0.9160\n",
      "Epoch 143/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.6005 - acc: 0.7997Epoch 00142: val_loss improved from 0.50185 to 0.49851, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.6003 - acc: 0.7998 - val_loss: 0.4985 - val_acc: 0.9175\n",
      "Epoch 144/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.5975 - acc: 0.8022Epoch 00143: val_loss improved from 0.49851 to 0.49514, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5973 - acc: 0.8022 - val_loss: 0.4951 - val_acc: 0.9175\n",
      "Epoch 145/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.5954 - acc: 0.8014Epoch 00144: val_loss improved from 0.49514 to 0.49283, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5952 - acc: 0.8014 - val_loss: 0.4928 - val_acc: 0.9180\n",
      "Epoch 146/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.5923 - acc: 0.8039Epoch 00145: val_loss improved from 0.49283 to 0.49000, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5922 - acc: 0.8039 - val_loss: 0.4900 - val_acc: 0.9185\n",
      "Epoch 147/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.5872 - acc: 0.8081Epoch 00146: val_loss improved from 0.49000 to 0.48563, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5855 - acc: 0.8095 - val_loss: 0.4856 - val_acc: 0.9217\n",
      "Epoch 148/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.5810 - acc: 0.8150Epoch 00147: val_loss improved from 0.48563 to 0.47862, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5798 - acc: 0.8163 - val_loss: 0.4786 - val_acc: 0.9067\n",
      "Epoch 149/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.5785 - acc: 0.8140Epoch 00148: val_loss improved from 0.47862 to 0.47402, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5772 - acc: 0.8154 - val_loss: 0.4740 - val_acc: 0.9070\n",
      "Epoch 150/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.5742 - acc: 0.8207Epoch 00149: val_loss improved from 0.47402 to 0.46981, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5740 - acc: 0.8208 - val_loss: 0.4698 - val_acc: 0.9072\n",
      "Epoch 151/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.5666 - acc: 0.8269Epoch 00150: val_loss improved from 0.46981 to 0.46572, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5665 - acc: 0.8270 - val_loss: 0.4657 - val_acc: 0.9067\n",
      "Epoch 152/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.5658 - acc: 0.8289Epoch 00151: val_loss improved from 0.46572 to 0.46159, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5646 - acc: 0.8297 - val_loss: 0.4616 - val_acc: 0.9072\n",
      "Epoch 153/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.5592 - acc: 0.8324Epoch 00152: val_loss improved from 0.46159 to 0.45825, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5580 - acc: 0.8330 - val_loss: 0.4582 - val_acc: 0.9067\n",
      "Epoch 154/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.5598 - acc: 0.8290Epoch 00153: val_loss improved from 0.45825 to 0.45443, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5588 - acc: 0.8299 - val_loss: 0.4544 - val_acc: 0.9067\n",
      "Epoch 155/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.5531 - acc: 0.8340Epoch 00154: val_loss improved from 0.45443 to 0.45074, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5518 - acc: 0.8347 - val_loss: 0.4507 - val_acc: 0.9042\n",
      "Epoch 156/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.5494 - acc: 0.8353Epoch 00155: val_loss improved from 0.45074 to 0.44665, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5481 - acc: 0.8360 - val_loss: 0.4466 - val_acc: 0.9048\n",
      "Epoch 157/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.5458 - acc: 0.8384Epoch 00156: val_loss improved from 0.44665 to 0.44256, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5457 - acc: 0.8383 - val_loss: 0.4426 - val_acc: 0.9205\n",
      "Epoch 158/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.5417 - acc: 0.8386Epoch 00157: val_loss improved from 0.44256 to 0.43862, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5416 - acc: 0.8386 - val_loss: 0.4386 - val_acc: 0.9260\n",
      "Epoch 159/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.5387 - acc: 0.8415Epoch 00158: val_loss improved from 0.43862 to 0.43515, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5379 - acc: 0.8412 - val_loss: 0.4351 - val_acc: 0.9255\n",
      "Epoch 160/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.5344 - acc: 0.8444Epoch 00159: val_loss improved from 0.43515 to 0.43119, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5337 - acc: 0.8444 - val_loss: 0.4312 - val_acc: 0.9098\n",
      "Epoch 161/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.5286 - acc: 0.8447Epoch 00160: val_loss improved from 0.43119 to 0.42773, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5277 - acc: 0.8453 - val_loss: 0.4277 - val_acc: 0.9205\n",
      "Epoch 162/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.5237 - acc: 0.8467Epoch 00161: val_loss improved from 0.42773 to 0.42343, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5230 - acc: 0.8471 - val_loss: 0.4234 - val_acc: 0.9205\n",
      "Epoch 163/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.5192 - acc: 0.8509Epoch 00162: val_loss improved from 0.42343 to 0.41982, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5180 - acc: 0.8512 - val_loss: 0.4198 - val_acc: 0.9242\n",
      "Epoch 164/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.5156 - acc: 0.8528Epoch 00163: val_loss improved from 0.41982 to 0.41792, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5157 - acc: 0.8525 - val_loss: 0.4179 - val_acc: 0.9235\n",
      "Epoch 165/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.5118 - acc: 0.8505Epoch 00164: val_loss improved from 0.41792 to 0.41244, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5103 - acc: 0.8513 - val_loss: 0.4124 - val_acc: 0.9410\n",
      "Epoch 166/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.5106 - acc: 0.8526Epoch 00165: val_loss improved from 0.41244 to 0.40904, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5099 - acc: 0.8529 - val_loss: 0.4090 - val_acc: 0.9405\n",
      "Epoch 167/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.5059 - acc: 0.8521Epoch 00166: val_loss improved from 0.40904 to 0.40572, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5057 - acc: 0.8521 - val_loss: 0.4057 - val_acc: 0.9405\n",
      "Epoch 168/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.5024 - acc: 0.8564Epoch 00167: val_loss improved from 0.40572 to 0.40224, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.5024 - acc: 0.8562 - val_loss: 0.4022 - val_acc: 0.9407\n",
      "Epoch 169/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.4979 - acc: 0.8559Epoch 00168: val_loss improved from 0.40224 to 0.39900, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4977 - acc: 0.8560 - val_loss: 0.3990 - val_acc: 0.9407\n",
      "Epoch 170/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4925 - acc: 0.8586Epoch 00169: val_loss improved from 0.39900 to 0.39593, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4911 - acc: 0.8594 - val_loss: 0.3959 - val_acc: 0.9407\n",
      "Epoch 171/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4903 - acc: 0.8606Epoch 00170: val_loss improved from 0.39593 to 0.39260, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4893 - acc: 0.8612 - val_loss: 0.3926 - val_acc: 0.9407\n",
      "Epoch 172/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4873 - acc: 0.8597Epoch 00171: val_loss improved from 0.39260 to 0.38927, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4866 - acc: 0.8600 - val_loss: 0.3893 - val_acc: 0.9412\n",
      "Epoch 173/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4870 - acc: 0.8584Epoch 00172: val_loss improved from 0.38927 to 0.38607, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4858 - acc: 0.8596 - val_loss: 0.3861 - val_acc: 0.9407\n",
      "Epoch 174/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.4794 - acc: 0.8617Epoch 00173: val_loss improved from 0.38607 to 0.38299, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4794 - acc: 0.8616 - val_loss: 0.3830 - val_acc: 0.9407\n",
      "Epoch 175/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.4771 - acc: 0.8598Epoch 00174: val_loss improved from 0.38299 to 0.37990, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4771 - acc: 0.8598 - val_loss: 0.3799 - val_acc: 0.9410\n",
      "Epoch 176/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.4742 - acc: 0.8628Epoch 00175: val_loss improved from 0.37990 to 0.37749, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4740 - acc: 0.8626 - val_loss: 0.3775 - val_acc: 0.9407\n",
      "Epoch 177/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4688 - acc: 0.8629Epoch 00176: val_loss improved from 0.37749 to 0.37431, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4675 - acc: 0.8639 - val_loss: 0.3743 - val_acc: 0.9407\n",
      "Epoch 178/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4684 - acc: 0.8627Epoch 00177: val_loss improved from 0.37431 to 0.37092, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4674 - acc: 0.8635 - val_loss: 0.3709 - val_acc: 0.9407\n",
      "Epoch 179/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4623 - acc: 0.8655Epoch 00178: val_loss improved from 0.37092 to 0.36819, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4617 - acc: 0.8656 - val_loss: 0.3682 - val_acc: 0.9407\n",
      "Epoch 180/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.4591 - acc: 0.8683Epoch 00179: val_loss improved from 0.36819 to 0.36502, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4591 - acc: 0.8683 - val_loss: 0.3650 - val_acc: 0.9412\n",
      "Epoch 181/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4551 - acc: 0.8683Epoch 00180: val_loss improved from 0.36502 to 0.36217, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4547 - acc: 0.8685 - val_loss: 0.3622 - val_acc: 0.9407\n",
      "Epoch 182/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4540 - acc: 0.8666Epoch 00181: val_loss improved from 0.36217 to 0.35922, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4532 - acc: 0.8672 - val_loss: 0.3592 - val_acc: 0.9407\n",
      "Epoch 183/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4515 - acc: 0.8656Epoch 00182: val_loss improved from 0.35922 to 0.35655, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4509 - acc: 0.8656 - val_loss: 0.3565 - val_acc: 0.9407\n",
      "Epoch 184/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4473 - acc: 0.8702Epoch 00183: val_loss improved from 0.35655 to 0.35373, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4465 - acc: 0.8706 - val_loss: 0.3537 - val_acc: 0.9407\n",
      "Epoch 185/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4448 - acc: 0.8698Epoch 00184: val_loss improved from 0.35373 to 0.35096, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4441 - acc: 0.8702 - val_loss: 0.3510 - val_acc: 0.9407\n",
      "Epoch 186/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4427 - acc: 0.8702Epoch 00185: val_loss improved from 0.35096 to 0.34806, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4420 - acc: 0.8705 - val_loss: 0.3481 - val_acc: 0.9407\n",
      "Epoch 187/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4394 - acc: 0.8705Epoch 00186: val_loss improved from 0.34806 to 0.34561, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4379 - acc: 0.8712 - val_loss: 0.3456 - val_acc: 0.9407\n",
      "Epoch 188/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.4378 - acc: 0.8669Epoch 00187: val_loss improved from 0.34561 to 0.34306, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4378 - acc: 0.8667 - val_loss: 0.3431 - val_acc: 0.9407\n",
      "Epoch 189/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.4338 - acc: 0.8717Epoch 00188: val_loss improved from 0.34306 to 0.34038, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4338 - acc: 0.8716 - val_loss: 0.3404 - val_acc: 0.9407\n",
      "Epoch 190/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4312 - acc: 0.8723Epoch 00189: val_loss improved from 0.34038 to 0.33908, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4306 - acc: 0.8730 - val_loss: 0.3391 - val_acc: 0.9405\n",
      "Epoch 191/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.4295 - acc: 0.8708Epoch 00190: val_loss improved from 0.33908 to 0.33573, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4294 - acc: 0.8708 - val_loss: 0.3357 - val_acc: 0.9407\n",
      "Epoch 192/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4237 - acc: 0.8765Epoch 00191: val_loss improved from 0.33573 to 0.33324, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4230 - acc: 0.8766 - val_loss: 0.3332 - val_acc: 0.9412\n",
      "Epoch 193/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.4237 - acc: 0.8711Epoch 00192: val_loss improved from 0.33324 to 0.33141, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4236 - acc: 0.8711 - val_loss: 0.3314 - val_acc: 0.9407\n",
      "Epoch 194/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4214 - acc: 0.8732Epoch 00193: val_loss improved from 0.33141 to 0.32877, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4210 - acc: 0.8733 - val_loss: 0.3288 - val_acc: 0.9407\n",
      "Epoch 195/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.4207 - acc: 0.8718Epoch 00194: val_loss improved from 0.32877 to 0.32651, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4209 - acc: 0.8717 - val_loss: 0.3265 - val_acc: 0.9407\n",
      "Epoch 196/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4147 - acc: 0.8758Epoch 00195: val_loss improved from 0.32651 to 0.32424, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4142 - acc: 0.8763 - val_loss: 0.3242 - val_acc: 0.9407\n",
      "Epoch 197/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4137 - acc: 0.8751Epoch 00196: val_loss improved from 0.32424 to 0.32192, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4134 - acc: 0.8749 - val_loss: 0.3219 - val_acc: 0.9407\n",
      "Epoch 198/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4135 - acc: 0.8723Epoch 00197: val_loss improved from 0.32192 to 0.32039, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4132 - acc: 0.8726 - val_loss: 0.3204 - val_acc: 0.9407\n",
      "Epoch 199/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4121 - acc: 0.8723Epoch 00198: val_loss improved from 0.32039 to 0.31793, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4111 - acc: 0.8727 - val_loss: 0.3179 - val_acc: 0.9407\n",
      "Epoch 200/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.4084 - acc: 0.8752Epoch 00199: val_loss improved from 0.31793 to 0.31589, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4078 - acc: 0.8757 - val_loss: 0.3159 - val_acc: 0.9410\n",
      "Epoch 201/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.4046 - acc: 0.8766Epoch 00200: val_loss improved from 0.31589 to 0.31379, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4046 - acc: 0.8766 - val_loss: 0.3138 - val_acc: 0.9412\n",
      "Epoch 202/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.4057 - acc: 0.8731Epoch 00201: val_loss improved from 0.31379 to 0.31175, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4059 - acc: 0.8729 - val_loss: 0.3117 - val_acc: 0.9410\n",
      "Epoch 203/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.4023 - acc: 0.8760Epoch 00202: val_loss improved from 0.31175 to 0.31065, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4021 - acc: 0.8761 - val_loss: 0.3106 - val_acc: 0.9407\n",
      "Epoch 204/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.4000 - acc: 0.8783Epoch 00203: val_loss improved from 0.31065 to 0.30767, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.4001 - acc: 0.8781 - val_loss: 0.3077 - val_acc: 0.9412\n",
      "Epoch 205/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3983 - acc: 0.8806Epoch 00204: val_loss improved from 0.30767 to 0.30590, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3982 - acc: 0.8806 - val_loss: 0.3059 - val_acc: 0.9407\n",
      "Epoch 206/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3961 - acc: 0.8816Epoch 00205: val_loss improved from 0.30590 to 0.30375, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3961 - acc: 0.8815 - val_loss: 0.3038 - val_acc: 0.9412\n",
      "Epoch 207/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3927 - acc: 0.8806Epoch 00206: val_loss improved from 0.30375 to 0.30215, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3927 - acc: 0.8805 - val_loss: 0.3022 - val_acc: 0.9407\n",
      "Epoch 208/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3942 - acc: 0.8793Epoch 00207: val_loss improved from 0.30215 to 0.30058, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3942 - acc: 0.8793 - val_loss: 0.3006 - val_acc: 0.9407\n",
      "Epoch 209/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3911 - acc: 0.8806Epoch 00208: val_loss improved from 0.30058 to 0.29859, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3911 - acc: 0.8805 - val_loss: 0.2986 - val_acc: 0.9407\n",
      "Epoch 210/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3901 - acc: 0.8813Epoch 00209: val_loss improved from 0.29859 to 0.29691, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3900 - acc: 0.8814 - val_loss: 0.2969 - val_acc: 0.9423\n",
      "Epoch 211/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3881 - acc: 0.8844Epoch 00210: val_loss improved from 0.29691 to 0.29524, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3881 - acc: 0.8844 - val_loss: 0.2952 - val_acc: 0.9418\n",
      "Epoch 212/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3870 - acc: 0.8834Epoch 00211: val_loss improved from 0.29524 to 0.29394, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3871 - acc: 0.8832 - val_loss: 0.2939 - val_acc: 0.9407\n",
      "Epoch 213/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3820 - acc: 0.8871Epoch 00212: val_loss improved from 0.29394 to 0.29196, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3821 - acc: 0.8868 - val_loss: 0.2920 - val_acc: 0.9418\n",
      "Epoch 214/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3807 - acc: 0.8854Epoch 00213: val_loss improved from 0.29196 to 0.29031, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3806 - acc: 0.8853 - val_loss: 0.2903 - val_acc: 0.9418\n",
      "Epoch 215/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3825 - acc: 0.8866Epoch 00214: val_loss improved from 0.29031 to 0.28853, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3824 - acc: 0.8867 - val_loss: 0.2885 - val_acc: 0.9420\n",
      "Epoch 216/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3776 - acc: 0.8870Epoch 00215: val_loss improved from 0.28853 to 0.28793, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3776 - acc: 0.8869 - val_loss: 0.2879 - val_acc: 0.9418\n",
      "Epoch 217/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3788 - acc: 0.8853Epoch 00216: val_loss improved from 0.28793 to 0.28525, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3786 - acc: 0.8852 - val_loss: 0.2853 - val_acc: 0.9423\n",
      "Epoch 218/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3756 - acc: 0.8902Epoch 00217: val_loss improved from 0.28525 to 0.28385, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3757 - acc: 0.8901 - val_loss: 0.2839 - val_acc: 0.9435\n",
      "Epoch 219/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3758 - acc: 0.8860Epoch 00218: val_loss improved from 0.28385 to 0.28233, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3757 - acc: 0.8859 - val_loss: 0.2823 - val_acc: 0.9418\n",
      "Epoch 220/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3724 - acc: 0.8887Epoch 00219: val_loss improved from 0.28233 to 0.28079, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3723 - acc: 0.8887 - val_loss: 0.2808 - val_acc: 0.9435\n",
      "Epoch 221/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3708 - acc: 0.8890Epoch 00220: val_loss improved from 0.28079 to 0.27979, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3708 - acc: 0.8890 - val_loss: 0.2798 - val_acc: 0.9430\n",
      "Epoch 222/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3707 - acc: 0.8884Epoch 00221: val_loss improved from 0.27979 to 0.27780, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3707 - acc: 0.8883 - val_loss: 0.2778 - val_acc: 0.9433\n",
      "Epoch 223/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3679 - acc: 0.8894Epoch 00222: val_loss improved from 0.27780 to 0.27620, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3681 - acc: 0.8892 - val_loss: 0.2762 - val_acc: 0.9423\n",
      "Epoch 224/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3665 - acc: 0.8907Epoch 00223: val_loss improved from 0.27620 to 0.27466, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3665 - acc: 0.8907 - val_loss: 0.2747 - val_acc: 0.9435\n",
      "Epoch 225/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3644 - acc: 0.8907Epoch 00224: val_loss improved from 0.27466 to 0.27333, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3645 - acc: 0.8905 - val_loss: 0.2733 - val_acc: 0.9435\n",
      "Epoch 226/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3645 - acc: 0.8884Epoch 00225: val_loss improved from 0.27333 to 0.27239, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3646 - acc: 0.8884 - val_loss: 0.2724 - val_acc: 0.9483\n",
      "Epoch 227/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3602 - acc: 0.8895Epoch 00226: val_loss improved from 0.27239 to 0.27037, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3603 - acc: 0.8897 - val_loss: 0.2704 - val_acc: 0.9487\n",
      "Epoch 228/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3616 - acc: 0.8876Epoch 00227: val_loss improved from 0.27037 to 0.26898, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3612 - acc: 0.8879 - val_loss: 0.2690 - val_acc: 0.9487\n",
      "Epoch 229/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3593 - acc: 0.8915Epoch 00228: val_loss improved from 0.26898 to 0.26760, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3594 - acc: 0.8914 - val_loss: 0.2676 - val_acc: 0.9485\n",
      "Epoch 230/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3567 - acc: 0.8922Epoch 00229: val_loss improved from 0.26760 to 0.26645, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3566 - acc: 0.8924 - val_loss: 0.2664 - val_acc: 0.9483\n",
      "Epoch 231/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3552 - acc: 0.8939Epoch 00230: val_loss improved from 0.26645 to 0.26479, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3549 - acc: 0.8942 - val_loss: 0.2648 - val_acc: 0.9492\n",
      "Epoch 232/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3564 - acc: 0.8914Epoch 00231: val_loss improved from 0.26479 to 0.26338, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3558 - acc: 0.8916 - val_loss: 0.2634 - val_acc: 0.9535\n",
      "Epoch 233/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3560 - acc: 0.8921Epoch 00232: val_loss improved from 0.26338 to 0.26176, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3558 - acc: 0.8922 - val_loss: 0.2618 - val_acc: 0.9553\n",
      "Epoch 234/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3533 - acc: 0.8918Epoch 00233: val_loss improved from 0.26176 to 0.26036, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3530 - acc: 0.8922 - val_loss: 0.2604 - val_acc: 0.9550\n",
      "Epoch 235/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3508 - acc: 0.8919Epoch 00234: val_loss improved from 0.26036 to 0.25903, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3500 - acc: 0.8923 - val_loss: 0.2590 - val_acc: 0.9540\n",
      "Epoch 236/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3471 - acc: 0.8956Epoch 00235: val_loss improved from 0.25903 to 0.25757, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3468 - acc: 0.8959 - val_loss: 0.2576 - val_acc: 0.9550\n",
      "Epoch 237/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3471 - acc: 0.8932Epoch 00236: val_loss improved from 0.25757 to 0.25623, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3471 - acc: 0.8934 - val_loss: 0.2562 - val_acc: 0.9553\n",
      "Epoch 238/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3469 - acc: 0.8928Epoch 00237: val_loss improved from 0.25623 to 0.25495, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3460 - acc: 0.8933 - val_loss: 0.2549 - val_acc: 0.9598\n",
      "Epoch 239/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3443 - acc: 0.8930Epoch 00238: val_loss improved from 0.25495 to 0.25372, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3436 - acc: 0.8935 - val_loss: 0.2537 - val_acc: 0.9598\n",
      "Epoch 240/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3442 - acc: 0.8934Epoch 00239: val_loss improved from 0.25372 to 0.25248, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3437 - acc: 0.8935 - val_loss: 0.2525 - val_acc: 0.9573\n",
      "Epoch 241/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3417 - acc: 0.8924Epoch 00240: val_loss improved from 0.25248 to 0.25117, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3413 - acc: 0.8928 - val_loss: 0.2512 - val_acc: 0.9573\n",
      "Epoch 242/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3412 - acc: 0.8937Epoch 00241: val_loss improved from 0.25117 to 0.24980, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3409 - acc: 0.8936 - val_loss: 0.2498 - val_acc: 0.9578\n",
      "Epoch 243/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3402 - acc: 0.8942Epoch 00242: val_loss improved from 0.24980 to 0.24870, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3403 - acc: 0.8942 - val_loss: 0.2487 - val_acc: 0.9573\n",
      "Epoch 244/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3410 - acc: 0.8918Epoch 00243: val_loss improved from 0.24870 to 0.24787, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3409 - acc: 0.8917 - val_loss: 0.2479 - val_acc: 0.9585\n",
      "Epoch 245/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3381 - acc: 0.8946Epoch 00244: val_loss improved from 0.24787 to 0.24633, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3379 - acc: 0.8951 - val_loss: 0.2463 - val_acc: 0.9585\n",
      "Epoch 246/3000\n",
      "3584/3600 [============================>.] - ETA: 0s - loss: 0.3339 - acc: 0.8962Epoch 00245: val_loss improved from 0.24633 to 0.24514, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3340 - acc: 0.8961 - val_loss: 0.2451 - val_acc: 0.9585\n",
      "Epoch 247/3000\n",
      "3456/3600 [===========================>..] - ETA: 0s - loss: 0.3358 - acc: 0.8949Epoch 00246: val_loss improved from 0.24514 to 0.24392, saving model to ./result/train_201611_11_16_53/model.h5\n",
      "3600/3600 [==============================] - 0s - loss: 0.3354 - acc: 0.8951 - val_loss: 0.2439 - val_acc: 0.9585\n",
      "Epoch 248/3000\n",
      "1920/3600 [===============>..............] - ETA: 0s - loss: 0.3397 - acc: 0.8916"
     ]
    }
   ],
   "source": [
    "model, train_history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.test(trainer.result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(repeat):\n",
    "#     trainer.init(input_dim, nb_classes, epoch=epoch, batch_size=batch_size, hidden_units=hidden_units,\n",
    "#                   time_step=time_step, learning_rate=learning_rate,\n",
    "#                   validation_split=validation_split, path_trained_dir=path_trained_dir)\n",
    "#     trainer.load_data()\n",
    "#     model, train_history = trainer.train()\n",
    "#     trainer.test(trainer.result_dir)\n",
    "#     path_trained_dir = trainer.result_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trainer.init(input_dim, nb_classes, epoch=epoch, batch_size=batch_size, hidden_units=hidden_units,\n",
    "#               time_step=time_step, learning_rate=learning_rate,\n",
    "#               validation_split=validation_split, path_trained_dir=path_trained_dir)\n",
    "# trainer.load_data()\n",
    "# model, train_history = trainer.train()\n",
    "# trainer.test(trainer.result_dir)\n",
    "# trainer.test('result/train_201610_27_18_58')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Only Testing\n",
    "\n",
    "# trainer = UNSW_Trainer(path_train, path_test, build_model, path_trained_dir=path_trained_dir)\n",
    "# trainer.load_data()\n",
    "# trainer.init(input_dim, nb_classes, epoch=epoch, batch_size=batch_size, hidden_units=hidden_units,\n",
    "#                                           time_step=time_step, learning_rate=learning_rate,\n",
    "#                                           validation_split=validation_split)\n",
    "# trainer.test('result/train_201610_26_17_08')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
